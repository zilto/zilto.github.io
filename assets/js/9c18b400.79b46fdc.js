"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[7465],{7810:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>p,frontMatter:()=>r,metadata:()=>s,toc:()=>m});var i=n(5893),a=n(1151);const r={slug:"pdf-summarizer",title:"Containerized PDF Summarizer with FastAPI and Hamilton",authors:"tj",tags:["Hamilton","OpenAI","LLM","FastAPI","Docker"]},o=void 0,s={permalink:"/blog/pdf-summarizer",source:"@site/blog/2023-08-18-pdf-summarizer/index.md",title:"Containerized PDF Summarizer with FastAPI and Hamilton",description:"Skip learning convoluted LLM-specific frameworks and write your first LLM application using regular Python functions and Hamilton! In this post, we\u2019ll present a containerized PDF summarizer powered by the OpenAI API. Its flow is encoded in Hamilton, which the FastAPI backend runs and exposes as an inference endpoint. The lightweight frontend uses Streamlit and exercises the backend. (GitHub repo)",date:"2023-08-18T00:00:00.000Z",tags:[{inline:!0,label:"Hamilton",permalink:"/blog/tags/hamilton"},{inline:!0,label:"OpenAI",permalink:"/blog/tags/open-ai"},{inline:!0,label:"LLM",permalink:"/blog/tags/llm"},{inline:!0,label:"FastAPI",permalink:"/blog/tags/fast-api"},{inline:!0,label:"Docker",permalink:"/blog/tags/docker"}],readingTime:14.58,hasTruncateMarker:!0,authors:[{name:"Thierry Jean",url:"https://github.com/zilto",imageURL:"https://github.com/zilto.png",key:"tj",page:null}],frontMatter:{slug:"pdf-summarizer",title:"Containerized PDF Summarizer with FastAPI and Hamilton",authors:"tj",tags:["Hamilton","OpenAI","LLM","FastAPI","Docker"]},unlisted:!1,prevItem:{title:"Retrieval augmented generation (RAG) with Streamlit, FastAPI, Weaviate, and Hamilton!",permalink:"/blog/rag"},nextItem:{title:"Featurization: Integrating Hamilton with Feast",permalink:"/blog/feast-hamilton"}},l={authorsImageUrls:[void 0]},m=[];function c(e){const t={a:"a",blockquote:"blockquote",img:"img",p:"p",...(0,a.a)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsxs)(t.p,{children:["Skip learning convoluted LLM-specific frameworks and write your first LLM application using regular Python functions and ",(0,i.jsx)(t.a,{href:"https://github.com/dagWorks-Inc/hamilton",children:"Hamilton"}),"! In this post, we\u2019ll present a containerized PDF summarizer powered by the ",(0,i.jsx)(t.a,{href:"https://platform.openai.com/docs/api-reference",children:"OpenAI API"}),". Its flow is encoded in Hamilton, which the ",(0,i.jsx)(t.a,{href:"https://fastapi.tiangolo.com/",children:"FastAPI"})," backend runs and exposes as an inference endpoint. The lightweight frontend uses ",(0,i.jsx)(t.a,{href:"https://docs.streamlit.io/",children:"Streamlit"})," and exercises the backend. (",(0,i.jsx)(t.a,{href:"https://github.com/DAGWorks-Inc/hamilton/tree/main/examples/LLM_Workflows/pdf_summarizer",children:"GitHub repo"}),")"]}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"Alt text",src:n(2947).Z+"",width:"975",height:"646"})}),"\n",(0,i.jsxs)(t.blockquote,{children:["\n",(0,i.jsxs)(t.p,{children:["crosspost from ",(0,i.jsx)(t.a,{href:"https://blog.dagworks.io/p/containerized-pdf-summarizer-with",children:"https://blog.dagworks.io/p/containerized-pdf-summarizer-with"})]}),"\n"]})]})}function p(e={}){const{wrapper:t}={...(0,a.a)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},2947:(e,t,n)=>{n.d(t,{Z:()=>i});const i=n.p+"assets/images/image-8afd5b643e3596877a57c4549fba352b.png"},1151:(e,t,n)=>{n.d(t,{Z:()=>s,a:()=>o});var i=n(7294);const a={},r=i.createContext(a);function o(e){const t=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function s(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),i.createElement(r.Provider,{value:t},e.children)}}}]);