"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[1424],{3882:(e,a,t)=>{t.r(a),t.d(a,{assets:()=>s,contentTitle:()=>l,default:()=>p,frontMatter:()=>i,metadata:()=>r,toc:()=>c});var n=t(5893),o=t(1151);const i={slug:"modular-llm",title:"Building a maintainable and modular LLM application stack with Hamilton",authors:"tj",tags:["Hamilton","vector search","OpenAI","Cohere","Weaviate","Pinecone","LanceDB"]},l=void 0,r={permalink:"/blog/modular-llm",source:"@site/blog/2023-07-11-modular-llm/index.md",title:"Building a maintainable and modular LLM application stack with Hamilton",description:"In this post, we\u2019re going to share how Hamilton can help you write modular and maintainable code for your large language model (LLM) application stack. Hamilton is great for describing any type of dataflow, which is exactly what you\u2019re doing when building an LLM powered application. With Hamilton you get strong software maintenance ergonomics, with the added benefit of being able to easily swap and evaluate different providers/implementations for components of your application.",date:"2023-07-11T00:00:00.000Z",formattedDate:"July 11, 2023",tags:[{label:"Hamilton",permalink:"/blog/tags/hamilton"},{label:"vector search",permalink:"/blog/tags/vector-search"},{label:"OpenAI",permalink:"/blog/tags/open-ai"},{label:"Cohere",permalink:"/blog/tags/cohere"},{label:"Weaviate",permalink:"/blog/tags/weaviate"},{label:"Pinecone",permalink:"/blog/tags/pinecone"},{label:"LanceDB",permalink:"/blog/tags/lance-db"}],readingTime:17.535,hasTruncateMarker:!0,authors:[{name:"Thierry Jean",url:"https://github.com/zilto",imageURL:"https://github.com/zilto.png",key:"tj"}],frontMatter:{slug:"modular-llm",title:"Building a maintainable and modular LLM application stack with Hamilton",authors:"tj",tags:["Hamilton","vector search","OpenAI","Cohere","Weaviate","Pinecone","LanceDB"]},unlisted:!1,prevItem:{title:"Simplify Prefect Workflow Creation and Maintenance with Hamilton",permalink:"/blog/prefect-hamilton"},nextItem:{title:"Simplify Airflow DAG Creation and Maintenance with Hamilton",permalink:"/blog/airflow-hamilton"}},s={authorsImageUrls:[void 0]},c=[];function m(e){const a={a:"a",blockquote:"blockquote",p:"p",...(0,o.a)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)(a.p,{children:["In this post, we\u2019re going to share how ",(0,n.jsx)(a.a,{href:"https://github.com/dagWorks-Inc/hamilton",children:"Hamilton"})," can help you write modular and maintainable code for your large language model (LLM) application stack. Hamilton is great for describing any type of ",(0,n.jsx)(a.a,{href:"https://en.wikipedia.org/wiki/Dataflow",children:"dataflow"}),", which is exactly what you\u2019re doing when building an LLM powered application. With Hamilton you get strong ",(0,n.jsx)(a.a,{href:"https://ceur-ws.org/Vol-3306/paper5.pdf",children:"software maintenance ergonomics"}),", with the added benefit of being able to easily swap and evaluate different providers/implementations for components of your application."]}),"\n",(0,n.jsxs)(a.blockquote,{children:["\n",(0,n.jsxs)(a.p,{children:["crosspost from ",(0,n.jsx)(a.a,{href:"https://blog.dagworks.io/p/building-a-maintainable-and-modular",children:"https://blog.dagworks.io/p/building-a-maintainable-and-modular"})]}),"\n"]})]})}function p(e={}){const{wrapper:a}={...(0,o.a)(),...e.components};return a?(0,n.jsx)(a,{...e,children:(0,n.jsx)(m,{...e})}):m(e)}},1151:(e,a,t)=>{t.d(a,{Z:()=>r,a:()=>l});var n=t(7294);const o={},i=n.createContext(o);function l(e){const a=n.useContext(i);return n.useMemo((function(){return"function"==typeof e?e(a):{...a,...e}}),[a,e])}function r(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:l(e.components),n.createElement(i.Provider,{value:a},e.children)}}}]);